import html
import pandas as pd
import csv
import re
import spacy
import json
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Enhanced preprocessing function
def preprocess_text(text):
    text = html.unescape(text)
    text = text.replace('\n', ' ').replace('\r', ' ')
    return text

def adjust_sentiment_based_on_keywords(text, original_sentiment):
    # Define keywords that might indicate a positive or negative sentiment
    positive_keywords = ['buy', 'bullish', 'gain', 'high', 'surge']
    negative_keywords = ['sell', 'short', 'drop', 'low', 'fall']

    # Only adjust if the original sentiment is Neutral
    if original_sentiment == 'Neutral':
        if any(keyword in text.lower() for keyword in positive_keywords):
            return 'Positive'
        elif any(keyword in text.lower() for keyword in negative_keywords):
            return 'Negative'

    # Return the original sentiment if no adjustments are made
    return original_sentiment


# Improved function to extract price/time targets using NER

def extract_entities(text):
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(text)

    entities = {"price_targets": [], "time_targets": []}
    for ent in doc.ents:
        if ent.label_ == "MONEY":
            # Clean the extracted price target here if necessary
            cleaned_price = re.sub(r'[^\d.]+', '', ent.text)  # Example: remove non-numeric characters
            if cleaned_price:  # Ensure it's not empty after cleaning
                entities["price_targets"].append(cleaned_price)
        elif ent.label_ in ["DATE", "TIME"]:
            # Add additional checks here if necessary to ensure relevance
            entities["time_targets"].append(ent.text)

    return entities

# Parameters
input_file = '10kdata.csv'
output_file = 'classified_data.csv'
index_file = 'last_index.txt'
batch_size = 5000  # Adjust based on your needs

# Load tokenizer and model separately
tokenizer = AutoTokenizer.from_pretrained("yiyanghkust/finbert-tone")
model = AutoModelForSequenceClassification.from_pretrained("yiyanghkust/finbert-tone")

# Adjust thresholds for sentiment classification
positive_threshold = 0.6  # Initial threshold for positive sentiment
negative_threshold = 0.6  # Initial threshold for negative sentiment

# Custom function for sentiment classification with adjusted thresholds
def custom_sentiment_classification(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    outputs = model(**inputs)
    logits = outputs.logits
    probabilities = torch.softmax(logits, dim=1).detach().cpu().numpy().flatten()

    # Check if the probability of positive sentiment exceeds the positive threshold
    if probabilities[1] >= positive_threshold:
        return 'Positive'
    # Check if the probability of negative sentiment exceeds the negative threshold
    elif probabilities[0] >= negative_threshold:
        return 'Negative'
    else:
        return 'Neutral'

# Load the data
print("Loading data...")
df = pd.read_csv(input_file)

# Determine where to start processing
try:
    with open(index_file, 'r') as file:
        start_from = int(file.read().strip())
        print(f"Resuming from index: {start_from}")
except FileNotFoundError:
    start_from = 0
    print("Starting from the beginning.")

# Process data in batches
for i in range(start_from, len(df), batch_size):
    end_index = min(i + batch_size, len(df))
    batch_indices = df.index[i:end_index]
    batch = df.loc[batch_indices]

    # Preprocess content
    df.loc[batch_indices, 'content'] = df.loc[batch_indices, 'content'].apply(preprocess_text)

    # Extract sentiment
    print("Extracting sentiment...")
    df.loc[batch_indices, 'sentiment'] = batch['content'].apply(custom_sentiment_classification)

    # Adjust sentiment based on keywords
    print("Adjusting sentiment based on keywords...")
    df.loc[batch_indices, 'sentiment'] = df.loc[batch_indices].apply(lambda row: adjust_sentiment_based_on_keywords(row['content'], row['sentiment']), axis=1)

    # Extract price/time targets
    print("Extracting entities...")
    df.loc[batch_indices, 'targets'] = df.loc[batch_indices, 'content'].apply(extract_entities)

    # Convert 'targets' column to a string representation that's CSV-friendly
    df.loc[batch_indices, 'targets'] = df.loc[batch_indices, 'targets'].apply(lambda x: str(x))

    batch = df.loc[batch_indices]

    # Save processed batch
    if i == 0:
        batch.to_csv(output_file, index=False, quoting=csv.QUOTE_ALL)
    else:
        batch.to_csv(output_file, mode='a', header=False, index=False, quoting=csv.QUOTE_ALL)

    # Update last processed index
    with open(index_file, 'w') as file:
        file.write(str(end_index))

    print(f"Batch processing complete. Processed up to index {end_index}.")

print("Data processing and saving complete.")
